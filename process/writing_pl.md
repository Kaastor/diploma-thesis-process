# Praktyczny i filozoficzny przewodnik po pisaniu pracy dyplomowej lub artykułu naukowego  
*Wersja 1.0 — „Plik startowy" dla początkujących i doświadczonych badaczy*

---

## Jak korzystać z tego dokumentu
Niniejszy dokument został zaprojektowany jako:
1) **Przewodnik dydaktyczny** (wyjaśnia *dlaczego* dobry warsztat pisarski jest istotny), oraz  
2) **Podręcznik referencyjny** (dostarcza praktycznych instrukcji, list kontrolnych i szablonów).

Pisarstwo naukowe nie polega jedynie na „opisaniu tego, co się wydarzyło". Jest to **konstrukcja przejrzystego, testowalnego argumentu**, który łączy pytanie badawcze z materiałem dowodowym i wnioskowaniem — tak aby sceptyczny, inteligentny czytelnik mógł zdecydować, czy ci uwierzyć, odtworzyć twoje wyniki, czy też na nich budować.

Korzystaj z tego dokumentu na trzy sposoby:
- **Przed pisaniem:** do zaprojektowania argumentacji i struktury.
- **W trakcie pisania:** do redagowania poszczególnych sekcji z właściwym celem i treścią.
- **Przed złożeniem:** do audytu jasności, rygoru, etyki, odtwarzalności i prezentacji.

---

## Spis treści
1. [Filozofia pisarstwa naukowego](#filozofia-pisarstwa-naukowego)  
2. [Zasady fundamentalne („prawa tego krajobrazu")](#zasady-fundamentalne-prawa-tego-krajobrazu)  
3. [Od pomysłu do artykułu: przebieg procesu badawczo-pisarskiego](#od-pomysłu-do-artykułu-przebieg-procesu-badawczo-pisarskiego)  
4. [Planowanie dokumentu: odbiorca, wkład i narracja](#planowanie-dokumentu-odbiorca-wkład-i-narracja)  
5. [Standardowe struktury (artykuł vs. praca dyplomowa)](#standardowe-struktury-artykuł-vs-praca-dyplomowa)  
6. [Przewodnik po sekcjach (z uzasadnieniem i instrukcją)](#przewodnik-po-sekcjach-z-uzasadnieniem-i-instrukcją)  
7. [Ryciny, tabele i materiał dowodowy wizualny](#ryciny-tabele-i-materiał-dowodowy-wizualny)  
8. [Cytowania, erudycja i uczciwość intelektualna](#cytowania-erudycja-i-uczciwość-intelektualna)  
9. [Metody, statystyka i odtwarzalność](#metody-statystyka-i-odtwarzalność)  
10. [Styl, jasność i ton naukowy](#styl-jasność-i-ton-naukowy)  
11. [Rewizja, informacja zwrotna i kontrola jakości](#rewizja-informacja-zwrotna-i-kontrola-jakości)  
12. [Etyka, autorstwo i odpowiedzialne prowadzenie badań](#etyka-autorstwo-i-odpowiedzialne-prowadzenie-badań)  
13. [Składanie pracy, recenzja naukowa i odpowiadanie recenzentom](#składanie-pracy-recenzja-naukowa-i-odpowiadanie-recenzentom)  
14. [Wskazówki specyficzne dla prac dyplomowych](#wskazówki-specyficzne-dla-prac-dyplomowych)  
15. [Typowe błędy (i jak ich unikać)](#typowe-błędy-i-jak-ich-unikać)  
16. [Praktyczne listy kontrolne](#praktyczne-listy-kontrolne)  
17. [Mini-szablony i banki fraz (stosować z rozwagą)](#mini-szablony-i-banki-fraz-stosować-z-rozwagą)  
18. [Aneks A — Uczenie głębokie: Rzetelne eksperymenty i odtwarzalne systemy](#aneks-a--uczenie-głębokie-rzetelne-eksperymenty-i-odtwarzalne-systemy)  
19. [Aneks B — Agentowa sztuczna inteligencja: Ewaluacja systemów bez autooszukiwania](#aneks-b--agentowa-sztuczna-inteligencja-ewaluacja-systemów-bez-autooszukiwania)  

---

# Filozofia pisarstwa naukowego

## Pisanie jest częścią metody naukowej
Wiedza naukowa jest wiedzą *publiczną*. Wynik, który nie może być zrozumiany, oceniony lub odtworzony, nie jest jeszcze w pełni naukowy. Pisanie nie jest zatem kosmetycznym etapem po zakończeniu „właściwej pracy"; jest **fundamentalnym instrumentem nauki**, porównywalnym z pomiarem i analizą.

### Centralne zobowiązanie filozoficzne
Pisarstwo naukowe powinno umożliwić czytelnikowi odpowiedź, przy minimalnym zgadywaniu, na następujące pytania:
- **Co było przedmiotem badania?**  
- **Co zostało wykonane?**  
- **Co odkryto?**  
- **Dlaczego powinniśmy temu wierzyć?**  
- **Co to oznacza — a czego nie oznacza?**

## Cel dobrej nauki: wiarygodna wiedza odporna na autooszukiwanie
Jeżeli pisarstwo naukowe stanowi publiczny interfejs nauki, to cel dobrej nauki można sformułować prosto:

**Wytwarzanie wiarygodnej wiedzy o świecie, w warunkach niepewności, w sposób umożliwiający audyt przez inne umysły.**

„Prawda" w nauce rzadko przybiera formę dramatycznego absolutu. Częściej jest to:
- pomiar z niepewnością,
- model przewidujący w znanym reżimie,
- wyjaśnienie, które przetrwało próby falsyfikacji,
- wynik pozostający stabilny przy wypróbowaniu rozsądnych alternatyw.

Dobra nauka dąży zatem do **minimalizacji błędów, których można uniknąć** (obciążenie, wyciek danych, zmienne zakłócające, artefakty pomiarowe, przeuczenie, selektywny dobór wyników) oraz do **maksymalizacji możliwości inspekcji** (jasne metody, przejrzyste założenia, kompletne raportowanie).

Praktycznym testem, czy uprawiasz dobrą naukę, nie jest pytanie „Czy to brzmi przekonująco?", lecz:

- **Czy nadal bym w to wierzył, gdybym starał się to obalić?**
- **Czy kompetentny sceptyk mógłby odtworzyć wynik na podstawie mojego opisu?**
- **Jeśli wynik jest błędny, czy czytelnik może dostrzec, gdzie mógł powstać błąd?**

Pisarstwo naukowe operacjonalizuje ten cel poprzez przekształcanie prywatnej pracy w publiczny, weryfikowalny łańcuch rozumowania.

## Artykuł/praca dyplomowa to argument, nie dziennik
Dokument naukowy nie jest chronologicznym zapisem twoich działań. Jest **ustrukturyzowanym argumentem**, w którym każda część pełni określoną funkcję w rozumowaniu czytelnika.

Użyteczny model mentalny:
- **Teza**: Co twierdzisz.
- **Materiał dowodowy**: Co zaobserwowałeś/zmierzyłeś/wyprowadziłeś.
- **Uzasadnienie**: Dlaczego ten materiał dowodowy wspiera tezę (założenia, teoria, logika, statystyka).
- **Zakres**: Gdzie ma zastosowanie, a gdzie może nie mieć.

## Jasność jest formą etyki
Niejednoznaczność marnuje czas, ukrywa błędy i może wprowadzać w błąd. W nauce niejasne pisarstwo nie jest nieszkodliwe: może zniekształcać interpretację i utrudniać replikację. Dąż do pisarstwa, które jest **precyzyjne, umiarkowane w twierdzeniach i jednoznaczne co do niepewności**.

---

# Zasady fundamentalne („prawa tego krajobrazu")

Te zasady obowiązują w różnych dyscyplinach. Konwencje się różnią, ale leżąca u podstaw logika pozostaje stabilna.

## 1) Projektowanie zorientowane na czytelnika
**Dlaczego:** Twój czytelnik nie posiada twojego kontekstu. Twoim zadaniem jest efektywnie go zrekonstruować.  
**Jak:** Sformułuj pytanie na wczesnym etapie, zdefiniuj terminy i utrzymuj spójny wątek od motywacji → przez metodę → wyniki → do znaczenia.

## 2) Jeden główny wkład na artykuł (zazwyczaj)
**Dlaczego:** Artykuł jest oceniany jako zintegrowana całość; zbyt wiele wkładów rozmywa przekaz i dezorientuje recenzentów.  
**Jak:** Napisz jednozdaniowe „oświadczenie o wkładzie" i upewnij się, że każda sekcja je wspiera.

## 3) Odtwarzalność to nie slogan; to dokumentacja
**Dlaczego:** Nauka postępuje dzięki weryfikacji i rozszerzaniu.  
**Jak:** Rejestruj pochodzenie danych, wybory parametrów, wykluczenia, preprocessing i decyzje analityczne. Uczyń „ścieżkę od surowych danych do wyniku" możliwą do inspekcji.

## 4) Prawdomówność ponad perswazję (kalibracja jako cnota)
**Dlaczego:** Dokumenty naukowe mogą przypadkowo stać się prezentacjami sprzedażowymi. Perswazja nie jest celem; celem jest trafne przekonanie.  
**Jak:** Formułuj twierdzenia proporcjonalne do materiału dowodowego, raportuj niepewność, ujawniaj negatywne wyniki gdy są istotne i oddzielaj pomiar od interpretacji. Preferuj bycie poprawnym i odtwarzalnym nad bycie imponującym i kruchym.

## 5) Oddzielaj obserwację od interpretacji
**Dlaczego:** Czytelnicy muszą rozróżnić, co *się wydarzyło*, od tego, co *uważasz, że to oznacza*.  
**Jak:** W Wynikach opisuj; w Dyskusji interpretuj. Gdy interpretujesz, oznacz to jako interpretację i określ założenia.

## 6) Precyzja przebija wielkość
**Dlaczego:** Nadmierne roszczenia są karane przez rzeczywistość (i recenzentów).  
**Jak:** Preferuj ograniczone stwierdzenia („w tym zbiorze danych…", „w tych warunkach…", „sugeruje") nad uniwersalne proklamacje.

## 7) Każda liczba potrzebuje kontekstu
**Dlaczego:** Liczby są bezsensowne bez jednostek, niepewności i warunków.  
**Jak:** Podawaj jednostki, wielkości prób, zmienność/niepewność (SD/SE/CI) oraz definicje metryk.

## 8) Pisanie to iteracyjna inżynieria
**Dlaczego:** Dobre artykuły nie są pisane; są przepisywane.  
**Jak:** Pisz wersję roboczą szybko, rewizuj strukturalnie, następnie dopracowuj zdania. Nie próbuj osiągnąć perfekcji w pierwszym podejściu.

---

# Od pomysłu do artykułu: przebieg procesu badawczo-pisarskiego

Solidny proces redukuje zarówno błędy, jak i niepokój.

## Krok A — Zdefiniuj pytanie badawcze
Dobre pytanie jest:
- **Konkretne** (nie „o X", ale „czy X wpływa na Y w warunkach Z?")
- **Odpowiadalne** dostępnymi metodami i zasobami
- **Interesujące** dla zdefiniowanej społeczności
- **Osadzone** w istniejącej pracy (wiesz, co liczyłoby się jako „nowe")

Produkt: 2–5-zdaniowe stwierdzenie:
1. Tło problemu  
2. Luka w wiedzy  
3. Twoje pytanie/hipoteza  
4. Twoje podejście  
5. Twój oczekiwany wkład

## Krok B — Zdecyduj, co liczy się jako materiał dowodowy
**Dlaczego:** Wiele projektów zawodzi na etapie pisania, ponieważ „materiał dowodowy" nigdy nie został zdefiniowany.  
**Jak:** Zdecyduj o:
- Pierwotnych miarach wynikowych
- Wtórnych miarach wynikowych
- Kryteriach włączenia/wykluczenia
- Liniach bazowych i porównaniach
- Warunkach niepowodzenia (co sfalsyfikowałoby twoją hipotezę?)

## Krok C — Prowadź dziennik badawczy, który może stać się Metodami
Utrzymuj żywy zapis:
- Instrumenty, wersje oprogramowania, parametry
- Warunki zbierania danych
- Odchylenia od planu i ich przyczyny
- Kroki czyszczenia danych
- Skrypty analityczne lub przepływy pracy

To nie jest biurokracja; to przyszły tekst Metod.

## Krok D — Pisz wcześniej, niż myślisz
Wczesne redagowanie ujawnia:
- brakujące kontrole
- niejasne definicje
- słabe pomiary
- luki logiczne

Pisanie jest narzędziem diagnostycznym.

---

# Planowanie dokumentu: odbiorca, wkład i narracja

## Zidentyfikuj swojego głównego czytelnika
Typowi „główni czytelnicy" to:
- Sceptyczny recenzent w twojej subdyscyplinie
- Członek komisji spoza twojej niszy (praca dyplomowa)
- Praktyk stosowany (inżynieria/klinika)
- Specjalista od metod (statystyka/ML)

**Jak:** Napisz 3-liniowy „profil czytelnika":
- Co już wiedzą
- W co wątpią
- Co muszą zobaczyć, aby zostać przekonani

## Zdefiniuj swój wkład w jednym zdaniu
Przykłady (formy generyczne):
- „Proponujemy metodę, która ___ i demonstrujemy ___ na ___."
- „Dostarczamy materiał dowodowy, że ___ poprzez pomiar ___ w warunkach ___."
- „Rozwiązujemy ___ poprzez udowodnienie/wyprowadzenie ___."
- „Tworzymy zbiór danych/narzędzie umożliwiające ___ i walidujemy je poprzez ___."

Jeśli nie możesz napisać tego zdania, artykuł nie jest jeszcze gotowy do zarysowania.

## Traktuj dokument jako oprowadzenie po rozumowaniu
Dokument naukowy odpowiada na sekwencję pytań czytelnika. Jeśli zaspokoisz te pytania po kolei, artykuł stanie się łatwy do śledzenia:
1. Dlaczego to ma znaczenie?
2. Co dokładnie jest nieznane?
3. Jakie jest twoje podejście?
4. Co odkryłeś?
5. Dlaczego powinienem w to wierzyć?
6. Co to implikuje?
7. Jakie są ograniczenia i następne kroki?

---

# Standardowe struktury (artykuł vs. praca dyplomowa)

## Typowy artykuł naukowy (IMRaD + ramowanie)
- Tytuł
- Abstrakt
- Wprowadzenie
- Metody
- Wyniki
- Dyskusja
- Wnioski (czasem połączone z Dyskusją)
- Bibliografia
- Załączniki / Materiał uzupełniający

## Typowa praca dyplomowa (modularna i eksplicytna)
Dwa powszechne wzorce prac dyplomowych:

### A) Praca monograficzna
- Wprowadzenie / Tło
- Przegląd literatury (czasem oddzielnie)
- Metody / Materiały
- Rozdziały wynikowe
- Dyskusja
- Wnioski + Przyszłe prace
- Załączniki (szczegółowe metody, dodatkowe analizy, notatki o kodzie/danych)

### B) Praca oparta na artykułach (praca przez publikację)
- Ogólne wprowadzenie
- 2–4 rozdziały w stylu manuskryptu (opublikowane/złożone artykuły)
- Integracyjna dyskusja/wnioski wiążące je razem
- Załączniki

**Kluczowa różnica:** Praca dyplomowa musi wykazać *biegłość, samodzielność i szerokość*; artykuł musi wykazać *skoncentrowany wkład*.

---

# Przewodnik po sekcjach (z uzasadnieniem i instrukcją)

## Tytuł
### Dlaczego istnieje
Tytuł jest narzędziem indeksującym i obietnicą: informuje czytelników, czy temat jest dla nich istotny.

### Jak go pisać
- Uwzględnij **główny obiekt** (metoda/system/zjawisko)
- Uwzględnij **działanie** (przewidywanie, mierzenie, analizowanie, ulepszanie)
- Uwzględnij **domenę** (zbiór danych, populacja, kontekst) gdy to konieczne

Unikaj:
- niejasnych słów („nowatorski", „ulepszony", „nowy") bez konkretu
- zbędnej pomysłowości (zapamiętywalność jest dobra; dwuznaczność nie)

---

## Abstrakt
### Dlaczego istnieje
Abstrakt jest często jedyną częścią, którą wielu czytelników przeczyta. Musi umożliwiać trafną selekcję i poprawną interpretację.

### Jak go pisać (logika strukturalna)
Silny abstrakt zazwyczaj zawiera:
1. **Kontekst** (1–2 zdania): przestrzeń problemowa  
2. **Luka** (1 zdanie): co jest brakujące/nieznane  
3. **Podejście** (1–2 zdania): co zrobiłeś  
4. **Wyniki** (1–3 zdania): kluczowe ustalenia ilościowe/jakościowe  
5. **Znaczenie** (1 zdanie): implikacje i zakres  
6. **Ograniczenia** (opcjonalnie, 1 zdanie): istotne ograniczenia

Częsty błąd: opisywanie tego, co zrobiłeś, ale nie tego, co odkryłeś.

---

## Wprowadzenie
### Dlaczego istnieje
Wprowadzenie konstruuje uzasadnienie i pozycjonuje twoją pracę w literaturze, kulminując w precyzyjnym pytaniu i wkładzie.

### Jak je pisać (niezawodny łuk)
Użyteczna struktura:
1. **Szeroki kontekst:** dlaczego obszar ma znaczenie  
2. **Zawężony kontekst:** co jest szczególnie trudne/nieznane  
3. **Mapa literatury:** co było próbowane i co pozostaje nierozwiązane  
4. **Stwierdzenie luki:** dokładnie brakujący element  
5. **Twoje podejście:** co robisz inaczej  
6. **Wkłady:** explicytna lista lub akapit  
7. **Mapa dokumentu:** krótki przewodnik po reszcie

Test sukcesu:
- Po przeczytaniu Wprowadzenia czytelnik powinien być w stanie przewidzieć, co zawrą Metody i Wyniki.

---

## Prace pokrewne / Przegląd literatury
*(Czasem część Wprowadzenia; często oddzielny rozdział w pracy dyplomowej.)*

### Dlaczego istnieje
Nauka jest kumulatywna. Musisz wykazać:
- że rozumiesz dziedzinę
- że szanujesz wcześniejszą pracę
- że twój wkład jest odrębny
- że twoje metody są odpowiednie

### Jak to zrobić dobrze
Nie pisz listy cytowań jak listy zakupów. Zamiast tego:
- Organizuj według **idei, podejść lub debat**, nie według chronologii autorów.
- Porównuj badania według: pytania, danych, metody, założeń, ustaleń, ograniczeń.
- Podkreślaj *dlaczego* istniejące wyniki nie rozstrzygają twojego pytania.

Uwzględnij:
- prace fundamentalne (kotwice koncepcyjne)
- najlepsze obecne metody/wyniki (stan wiedzy)
- blisko sąsiadujące podejścia (aby uniknąć recenzji „przeoczyłeś X")

Wskazówka dla prac dyplomowych: przegląd literatury często pełni jednocześnie funkcję *samouczka*. Ucz krajobrazu, potem lokalizuj swoją pracę.

---

## Metody (lub Materiały i metody)
### Dlaczego istnieje
Metody są kontraktem umożliwiającym reprodukcję i poprawną interpretację. Wyjaśniają *jak twój materiał dowodowy został wytworzony*.

### Jak je pisać
Sekcja Metod powinna umożliwić kompetentnemu badaczowi:
- replikację twojej procedury, lub
- implementację równoważnej procedury, oraz
- zrozumienie, dlaczego twoje wybory są zasadne

Uwzględnij, odpowiednio:
- Projekt badania (eksperymentalny/obserwacyjny/symulacyjny/teoretyczny)
- Źródła danych i protokół zbierania
- Uczestnicy/próbki/materiały oraz kryteria włączenia/wykluczenia
- Zmienne/cechy i definicje operacyjne
- Instrumenty i kalibracja
- Preprocessing i kontrola jakości
- Plan analizy statystycznej (testy/modele, założenia, korekty)
- Oprogramowanie, wersje, sprzęt (dla prac obliczeniowych)
- Hiperparametry, protokół treningu, strategia walidacji (ML)
- Zgody etyczne i świadoma zgoda (badania z ludźmi/zwierzętami/terenowe)

#### Filozofia Metod: eksponuj stopnie swobody
Czytelnicy powinni widzieć, gdzie wybory mogły być dokonane inaczej:
- alternatywny preprocessing
- alternatywne specyfikacje modelu
- kryteria selekcji
- reguły zatrzymania
- obsługa wartości odstających

Gdy dokonałeś wyborów, podaj:
- co zrobiłeś
- dlaczego to zrobiłeś
- jakie sprawdziany wrażliwości przeprowadziłeś (jeśli w ogóle)

---

## Wyniki
### Dlaczego istnieje
Wyniki dostarczają materiał dowodowy, jasno i bez inflacji retorycznej.

### Jak je pisać
- Prezentuj wyniki w tej samej kolejności co twoje pytania/hipotezy.
- Dla każdego wyniku: **co zmierzono, u kogo/w czym, w jakich warunkach, z jaką niepewnością**.
- Preferuj wielkości efektów i przedziały nad samo „istotność".
- Używaj rycin/tabel dla gęstej informacji; używaj tekstu, aby kierować interpretacją tego, co czytelnik powinien zauważyć.

Unikaj:
- ponownego wyjaśniania Metod
- głębokiego interpretowania (zostaw na Dyskusję)
- selektywnego raportowania („cherry-picking")

Silna sekcja Wyników to dobrze oświetlony pokój: nic ważnego nie jest ukryte w cieniu.

---

## Dyskusja
### Dlaczego istnieje
Dyskusja odpowiada na pytania: „I co z tego?" oraz „Dlaczego mam w to wierzyć?" jednocześnie uczciwie przedstawiając ograniczenia.

### Jak ją pisać (produktywna sekwencja)
1. **Podsumowanie kluczowych ustaleń** (nie kopia Wyników)  
2. **Interpretacja:** mechanizmy, wyjaśnienia, zgodność z teorią  
3. **Porównanie z wcześniejszą pracą:** zgodności, rozbieżności, przyczyny  
4. **Solidność:** sprawdziany wrażliwości, założenia, zagrożenia dla trafności  
5. **Ograniczenia:** czego nie możesz twierdzić i dlaczego  
6. **Implikacje:** dla teorii, praktyki lub przyszłych badań  
7. **Następne kroki:** konkretne i realistyczne kierunki

Znakiem dojrzałości jest Dyskusja, która jest jednocześnie pewna siebie i ostrożna:
- pewna siebie co do tego, co twój materiał dowodowy wspiera
- ostrożna co do tego, czego nie wspiera

---

## Wnioski
### Dlaczego istnieje
Wnioski kompresują wkład do trwałej formy.

### Jak je pisać
- Powtórz wkład i główne ustalenia prostym językiem.
- Podkreśl zakres (gdzie ma zastosowanie) i ograniczenia (gdzie może nie mieć).
- Zakończ przyszłościowym, ale ugruntowanym stwierdzeniem (przyszłe prace, zastosowania, otwarte pytania).

Unikaj wprowadzania nowych wyników.

---

## Podziękowania, finansowanie i ujawnienia
### Dlaczego istnieje
Badania są społeczne i finansowe. Przejrzystość redukuje ukryty wpływ.

### Jak to pisać
- Podziękuj za pomoc techniczną, informację zwrotną, zasoby.
- Wymień źródła finansowania.
- Zadeklaruj konflikty interesów (finansowe, osobiste, instytucjonalne).

---

# Ryciny, tabele i materiał dowodowy wizualny

## Filozofia: ryciny to widoczne argumenty
Dobra rycina nie jest dekoracją. Jest **skompresowanym materiałem dowodowym**.

## Ogólne zasady
- Każda rycina musi odpowiadać na pytanie: *Czego czytelnik ma się nauczyć?*
- Twórz ryciny interpretowalne bez tekstu głównego:
  - oznaczone osie z jednostkami
  - czytelne legendy
  - zdefiniowane skróty
  - podpisy wyjaśniające co, jak i kluczowy wniosek

## Podpisy: użyteczna struktura
Silny podpis często zawiera:
1. Co jest pokazane (dane/model/warunki)
2. Jak to wyprodukowano (krótko)
3. Co czytelnik powinien zauważyć (główny wzorzec)

## Tabele: gdy dokładne wartości mają znaczenie
Używaj tabel dla:
- wartości parametrów
- wyników ablacji
- rozkładów demograficznych
- współczynników modeli statystycznych

Unikaj tabel dla wzorców lepiej widocznych jako wykresy.

## Zasady integralności
- Nie manipuluj osiami ani skalami w celu wprowadzenia w błąd.
- Raportuj wykluczenia i transformacje.
- Utrzymuj spójne skale między porównywalnymi wykresami, gdy to wykonalne.

---

# Cytowania, erudycja i uczciwość intelektualna

## Dlaczego cytujemy
Cytowania pełnią co najmniej cztery funkcje:
1. **Uznanie** (uczciwość intelektualna)
2. **Wsparcie** (materiał dowodowy dla twierdzeń)
3. **Kontekst** (umiejscowienie pracy w rodowodzie)
4. **Nawigacja** (pomoc czytelnikom w znalezieniu szczegółów)

## Co cytować
Cytuj, gdy:
- używasz idei, metody, zbioru danych lub narzędzia, które nie są pierwotnie twoje
- podajesz nietrywialne fakty niebędące wiedzą powszechną u twojego odbiorcy
- porównujesz z wcześniejszymi wynikami
- używasz konkretnej definicji lub twierdzenia teoretycznego

## Dobra praktyka cytowania
- Preferuj źródła pierwotne (oryginalne artykuły), gdy to możliwe.
- Cytuj przeglądy dla szerokich przeglądów, ale nie zastępuj cytowań pierwotnych przeglądami.
- Unikaj łańcuchów cytowań („zacytowałem artykuł, który cytował oryginał").
- Upewnij się, że cytowania rzeczywiście wspierają twierdzenie, do którego je dołączasz.

## Unikaj „plagiatu cytacji"
Parafrazowanie czyjeś idei nadal wymaga cytowania. Zmiana słownictwa nie zmienia własności idei.

---

# Metody, statystyka i odtwarzalność

## Komponenty odtwarzalności
W zależności od dziedziny odtwarzalność może wymagać:
- dostępności danych (lub procedury dostępu)
- dostępności kodu (lub szczegółowego pseudokodu)
- dokumentacji parametrów/hiperparametrów
- losowych ziaren i szczegółów środowiska
- pełnej specyfikacji modelu
- prerejestracji (gdzie stosowne)
- kompletnego raportowania wykluczeń i obsługi brakujących danych

## Statystyka: zasady raportowania
- Raportuj **wielkości efektów** i **niepewność** (przedziały ufności/wiarygodności, gdzie stosowne).
- Raportuj **wielkości prób** i sposób ich doboru (analiza mocy lub uzasadnienie).
- Zajmij się **porównaniami wielokrotnymi**, jeśli testujesz wiele hipotez.
- Rozróżnij analizy **konfirmacyjne** (sterowane hipotezą) od **eksploracyjnych**.
- Bądź jednoznaczny co do **założeń** (normalność, niezależność, dopasowanie modelu).

## Solidność i wrażliwość
Silna praca często zawiera:
- alternatywne wiarygodne specyfikacje modelu
- badania ablacyjne (co się stanie, jeśli usuniesz komponenty?)
- sprawdzenia pod kątem wycieku danych (ML)
- wrażliwość na wartości odstające i braki
- analizy podgrup (z ostrożnością i przejrzystością)

---

# Styl, jasność i ton naukowy

## Cel: precyzja z czytelnością
Proza naukowa powinna być:
- dokładna
- jednoznaczna co do niepewności
- zwięzła, ale nie tajemnicza

## Preferowane nawyki
- Definiuj terminy przy pierwszym użyciu.
- Używaj spójnej terminologii (nie nadawaj tej samej koncepcji różnych nazw wielokrotnie).
- Preferuj stronę czynną, gdy wyjaśnia odpowiedzialność („Zmierzyliśmy…").
- Używaj strony biernej, gdy wykonawca jest nieistotny, a metoda ma znaczenie („Próbki inkubowano…").
- Pisz krótkie zdania przy opisywaniu procedur lub wyników.
- Umieszczaj główny punkt na początku zdania; szczegóły później.

## Ostrożność sformułowań: dyscyplinowany rodzaj
Ostrożność sformułowań nie jest słabością; to kalibracja dokładności.
- Używaj „sugeruje", gdy materiał dowodowy jest pośredni.
- Używaj „demonstruje", gdy materiał dowodowy bezpośrednio wspiera twierdzenie przy określonych założeniach.
- Używaj „może" tylko wtedy, gdy możesz wyjaśnić mechanizm lub niepewność.

## Liczby i symbole
- Definiuj wszystkie symbole i zmienne.
- Podawaj jednostki.
- Używaj spójnych cyfr znaczących (odzwierciedlających precyzję pomiaru).

---

# Rewizja, informacja zwrotna i kontrola jakości

## Rewizja to nie korekta
Istnieją różne poziomy rewizji:
1. **Rewizja argumentu:** Czy odpowiadasz na właściwe pytanie z właściwym materiałem dowodowym?
2. **Rewizja struktury:** Czy kolejność odpowiada logice czytelnika?
3. **Rewizja akapitów:** Czy każdy akapit ma jeden cel?
4. **Rewizja zdań:** Czy zdania są jasne i poprawne?
5. **Korekta:** Literówki, formatowanie, spójność

Nie zaczynaj od poziomu 5.

## Praktyczne techniki rewizji
- **Konspekt odwrotny:** Po napisaniu wersji roboczej napisz jedno zdanie na akapit opisujące jego rolę. Usuń lub przenieś akapity, które nie służą argumentowi.
- **Symulacja czytelnika:** Daj artykuł koledze i poproś o podsumowanie twojego wkładu i głównego materiału dowodowego. Jeśli nie potrafią, artykuł nie jest jeszcze jasny.
- **Sprawdzanie najpierw rycin:** Czy ktoś może zrozumieć twoje wyniki tylko z rycin i podpisów?

## Etykieta informacji zwrotnej (i skuteczność)
- Proś o konkretną informację zwrotną: „Czy wkład jest jasny?" „Czy Metody są replikowalne?" „Czy Rycina 2 wspiera Twierdzenie A?"
- Zaakceptuj, że krytyka dotyczy artefaktu, nie twojej wartości.

---

# Etyka, autorstwo i odpowiedzialne prowadzenie badań

## Etyka jest szersza niż zgody
Etyka obejmuje:
- uczciwe raportowanie
- szacunek dla uczestników i społeczności
- unikanie szkody
- przejrzystość co do niepewności i ograniczeń
- właściwe przypisanie autorstwa

## Autorstwo (zasady ogólne)
Standardy autorstwa różnią się w zależności od dziedziny, ale powszechne oczekiwania obejmują:
- znaczący wkład w koncepcję/projekt, wykonanie lub interpretację
- udział w redagowaniu lub krytycznej rewizji
- odpowiedzialność za integralność pracy

Omawiaj autorstwo wcześnie, koryguj w miarę ewolucji ról i dokumentuj decyzje.

## Etyka danych
- Chroń prywatność i wrażliwe informacje.
- Przestrzegaj wymogów instytucjonalnych i prawnych.
- Unikaj „teatru deidentyfikacji" (zakładania, że usunięcie imion jest wystarczające).
- Dokumentuj zgodę i zasady zarządzania danymi.

---

# Składanie pracy, recenzja naukowa i odpowiadanie recenzentom

## Strategia składania
- Dopasuj swój artykuł do zakresu i standardów czasopisma/konferencji.
- Przestrzegaj wymogów formatowania i raportowania.
- Upewnij się, że ryciny, bibliografia i materiały uzupełniające spełniają specyfikacje.

## Recenzja naukowa: właściwe nastawienie
Recenzenci nie są wszechwiedzący; są ograniczonymi, sceptycznymi czytelnikami.
Traktuj recenzje jako:
- test jasności
- test rygoru
- test nowości i pozycjonowania

## Pisanie odpowiedzi recenzentom
Silna odpowiedź jest:
- uprzejma i konkretna
- ustrukturyzowana (punkt po punkcie)
- przejrzysta co do zmian (z lokalizacjami)
- gotowa do ustępstw i poprawy, ale nie do porzucenia logiki

Gdy się nie zgadzasz:
- powtórz obawę recenzenta uczciwie
- dostarcz materiał dowodowy lub rozumowanie
- wyjaśnij manuskrypt odpowiednio (często możesz poprawić jasność, nawet jeśli recenzent „się myli")

---

# Wskazówki specyficzne dla prac dyplomowych

## Praca dyplomowa jest świadectwem terminowania
Praca dyplomowa demonstruje:
- kompetencję techniczną
- samodzielne myślenie
- opanowanie literatury
- zdolność do planowania i wykonywania badań
- zdolność do odpowiedzialnego komunikowania

## Wybory struktury pracy dyplomowej
Jeśli twoja praca jest długa, musi być:
- nawigowalna (jasne cele rozdziałów, spójna notacja)
- wewnętrznie spójna (te same definicje i założenia)
- uczciwa co do tego, co jest oryginalne vs. tło

## Praca z promotorem i komisją
- Uzgodnij oczekiwania wcześnie: zakres, liczba rozdziałów, poziom wkładu, terminy.
- Traktuj spotkania jak przeglądy projektowe: przynoś konspekty, decyzje i otwarte pytania.
- Prowadź „dziennik decyzji" (wybory metodologiczne, zmiany, uzasadnienia).

## Obrona (gdzie ma zastosowanie)
Obrona jest ustnym testem:
- twojego modelu problemu
- twojego materiału dowodowego i rozumowania
- twojej świadomości ograniczeń
- twojej zdolności do przemyślanej odpowiedzi pod presją

Zbuduj prezentację wokół:
- pytania
- twojego podejścia
- 2–4 kluczowych wyników
- implikacji i ograniczeń

---

# Typowe błędy i jak ich unikać

## 1) „Wszystko jest ważne"
**Symptom:** przesadnie rozbudowane wprowadzenie, nieskoncentrowane wyniki.  
**Rozwiązanie:** wybierz jeden główny wkład i podporządkuj mu wszystko inne.

## 2) Metody zbyt niejasne do odtworzenia
**Symptom:** brakujące wybory parametrów, niejasne próbkowanie, nieznany preprocessing.  
**Rozwiązanie:** pisz Metody tak, jakby rywalizujące laboratorium miało je replikować i krytykować.

## 3) Wyniki bez niepewności
**Symptom:** tylko oszacowania punktowe i wartości p.  
**Rozwiązanie:** uwzględnij niepewność, wielkości efektów i założenia.

## 4) Dyskusja, która przesadza z twierdzeniami
**Symptom:** język przyczynowy bez projektu przyczynowego, uogólnianie poza dane.  
**Rozwiązanie:** jawnie podaj warunki zakresu i zagrożenia dla trafności.

## 5) Przegląd literatury jako lista
**Symptom:** „Autor A zrobił X. Autor B zrobił Y."  
**Rozwiązanie:** organizuj według tematów, debat, metod; porównuj i syntetyzuj.

## 6) Ryciny, które nie niosą swojego ciężaru
**Symptom:** niejasne osie, brakujące jednostki, podpisy, które nic nie mówią.  
**Rozwiązanie:** traktuj każdą rycinę jako samodzielny argument.

---

# Praktyczne listy kontrolne

## Lista kontrolna przed pisaniem
- [ ] Potrafię sformułować pytanie badawcze w jednym zdaniu.
- [ ] Potrafię sformułować główny wkład w jednym zdaniu.
- [ ] Znam docelowego odbiorcę/czasopismo.
- [ ] Zdefiniowałem, co liczy się jako materiał dowodowy i sukces.
- [ ] Mam minimalny zestaw rycin/tabel, które poniosą Wyniki.

## Lista kontrolna Wprowadzenia
- [ ] Wyjaśniam, dlaczego temat ma znaczenie (dla tego odbiorcy).
- [ ] Podaję konkretną lukę, którą moja praca adresuje.
- [ ] Pozycjonuję swoją pracę względem kluczowych wcześniejszych podejść.
- [ ] Podaję wkłady jawnie.
- [ ] Dostarczam mapę dokumentu.

## Lista kontrolna Metod
- [ ] Projekt, źródła danych i dobór próby są jawne.
- [ ] Wszystkie zmienne/metryki są zdefiniowane operacyjnie.
- [ ] Preprocessing i wykluczenia są udokumentowane.
- [ ] Wybory statystyczne/modelowe są uzasadnione i odtwarzalne.
- [ ] Narzędzia, wersje i kluczowe parametry są zapisane.
- [ ] Zgody etyczne/świadoma zgoda są podane, jeśli dotyczy.

## Lista kontrolna Wyników
- [ ] Wyniki odpowiadają sformułowanym pytaniom/hipotezom.
- [ ] Wielkości prób są raportowane.
- [ ] Niepewność jest raportowana odpowiednio.
- [ ] Ryciny i tabele są interpretowalne i przywołane w tekście.
- [ ] Negatywne/zerowe wyniki są raportowane, gdy istotne.

## Lista kontrolna Dyskusji
- [ ] Podsumowuję kluczowe ustalenia dokładnie.
- [ ] Interpretuję wyniki z odpowiednią ostrożnością.
- [ ] Porównuję z wcześniejszą pracą uczciwie.
- [ ] Podaję ograniczenia i zagrożenia dla trafności.
- [ ] Unikam twierdzeń przekraczających mój projekt/dane.

## Lista kontrolna końcowej korekty
- [ ] Terminologia jest spójna.
- [ ] Wszystkie symbole/skróty są zdefiniowane.
- [ ] Wszystkie twierdzenia wymagające cytowań mają cytowania.
- [ ] Bibliografia jest kompletna i poprawnie sformatowana.
- [ ] Ryciny mają jednostki, czytelny tekst i informacyjne podpisy.
- [ ] Abstrakt odzwierciedla rzeczywiste ustalenia.

---

# Mini-szablony i banki fraz (stosować z rozwagą)

To są rusztowania, nie substytuty myślenia.

## Oświadczenia o wkładzie
- „Niniejsza praca wnosi trzy wkłady: (1) ___, (2) ___ oraz (3) ___."
- „Wprowadzamy ___ i pokazujemy, że ___ w porównaniu z ___ na ___."
- „Dostarczamy materiał dowodowy, że ___ poprzez pomiar ___ w warunkach ___."

## Stwierdzenia luki
- „Jednakże istniejące badania nie rozwiązały ___, ponieważ ___."
- „Wcześniejsze podejścia są ograniczone przez ___, co motywuje ___."

## Ograniczenia
- „Nasze ustalenia są ograniczone do ___, ponieważ ___."
- „Kluczowym założeniem naszej analizy jest ___; naruszenia tego założenia mogą prowadzić do ___."

## Odpowiedzialna interpretacja
- „Te wyniki sugerują ___ w testowanych warunkach."
- „Alternatywnym wyjaśnieniem jest ___; przyszłe prace mogłyby rozróżnić te możliwości poprzez ___."

---

## Uwaga końcowa: cicha cnota pisarstwa naukowego
Pisarstwo naukowe jest niezwykłym rzemiosłem, ponieważ wymaga dwóch cnót jednocześnie:
- **Ambicji** (powiedzenia czegoś nowego i użytecznego), oraz
- **Pokory** (niepowiedzenia więcej, niż pozwala materiał dowodowy).

Gdy te cnoty są w równowadze, dokument staje się czymś więcej niż raportem: staje się godnym zaufania elementem wspólnej maszynerii wiedzy.

---

# A Practical and Philosophical Guide to Writing a Thesis or Scientific Paper  
*Version 1.1 — Includes Deep Learning + Agentic AI annexes*

---

## How to use this document
This file is designed as both:
1) **A pedagogical guide** (it explains the *why* behind good scientific writing), and  
2) **A reference manual** (it provides actionable *how-to* steps, checklists, and templates).

Scientific writing is not merely "writing down what happened." It is **the construction of a transparent, testable argument** that connects a question to evidence to inference—so that a skeptical, intelligent reader can decide whether to believe you, reproduce you, or build upon you.

Use it in three ways:
- **Before you write:** to design your argument and structure.
- **While you write:** to draft each section with correct purpose and content.
- **Before you submit:** to audit clarity, rigor, ethics, reproducibility, and presentation.

---

## Table of contents
1. [The philosophy of scientific writing](#the-philosophy-of-scientific-writing)  
2. [Core principles (the "laws of the land")](#core-principles-the-laws-of-the-land)  
3. [From idea to paper: the research-to-writing pipeline](#from-idea-to-paper-the-research-to-writing-pipeline)  
4. [Planning the document: audience, contribution, and story](#planning-the-document-audience-contribution-and-story)  
5. [Standard structures (paper vs. thesis)](#standard-structures-paper-vs-thesis)  
6. [Section-by-section guide (with why + how)](#section-by-section-guide-with-why--how)  
7. [Figures, tables, and visual evidence](#figures-tables-and-visual-evidence)  
8. [Citations, scholarship, and intellectual honesty](#citations-scholarship-and-intellectual-honesty)  
9. [Methods, statistics, and reproducibility](#methods-statistics-and-reproducibility)  
10. [Style, clarity, and scientific tone](#style-clarity-and-scientific-tone)  
11. [Revision, feedback, and quality control](#revision-feedback-and-quality-control)  
12. [Ethics, authorship, and responsible research](#ethics-authorship-and-responsible-research)  
13. [Submission, peer review, and responding to reviewers](#submission-peer-review-and-responding-to-reviewers)  
14. [Thesis-specific guidance](#thesis-specific-guidance)  
15. [Common failure modes (and how to avoid them)](#common-failure-modes-and-how-to-avoid-them)  
16. [Practical checklists](#practical-checklists)  
17. [Mini-templates and phrase banks (use judiciously)](#mini-templates-and-phrase-banks-use-judiciously)  
18. [Annex A — Deep Learning: Truthful Experiments and Reproducible Systems](#annex-a--deep-learning-truthful-experiments-and-reproducible-systems)  
19. [Annex B — Agentic AI: Evaluating Systems Without Fooling Yourself](#annex-b--agentic-ai-evaluating-systems-without-fooling-yourself)  

---

# Aneks A — Uczenie głębokie: Rzetelne eksperymenty i odtwarzalne systemy

## A.0 Cel i zakres
Ten aneks jest przeznaczony na moment, gdy myślisz:

> „Implementuję system uczenia głębokiego. Jak zapewnić, że moje wyniki są *rzetelne* — że odzwierciedlają rzeczywistą wydajność, a nie przypadki eksperymentalne?"

Eksperymenty uczenia głębokiego są wyjątkowo podatne na **autooszukiwanie przez stopnie swobody**:
- potoki danych z ukrytym wyciekiem,
- stochastyczny trening i kruche usprawnienia,
- dostrajanie hiperparametrów, które cicho korzysta ze zbioru testowego,
- porównania uczynione nieuczciwymi przez niedopasowaną moc obliczeniową lub wysiłek dostrajania,
- ewaluacja, która subtelnie różni się od rzeczywistego wdrożenia.

Celem nie jest perfekcja. Celem są **uczciwe, stabilne wnioski**, które przetrwają sceptycyzm.

---

## A.1 Określ twierdzenie, które faktycznie chcesz sformułować (zdolność vs. wynik systemu)
Zanim cokolwiek uruchomisz, napisz jedno zdanie:

- **Typ twierdzenia 1 — Twierdzenie algorytmiczne/o zdolności:**  
  „W kontrolowanych warunkach metoda X poprawia metrykę Y względem linii bazowej B."

- **Typ twierdzenia 2 — Twierdzenie o systemie:**  
  „Kompletny potok (dane + trening + ograniczenia wnioskowania) osiąga Y w kontekście Z."

To są różne rzeczy. Jeśli ich nie rozdzielisz, źle zinterpretujesz własne wyniki.

---

## A.2 Projekt eksperymentu: kontrole, linie bazowe i uczciwość
### A.2.1 Wybierz linie bazowe, które możesz obronić
Twoja linia bazowa powinna być:
- **konkurencyjna** (nie słomiana kukła),
- **poprawnie dostrojona** (podobny budżet dostrajania),
- **udokumentowana** (dokładna konfiguracja, wersje).

Częstym błędem metodologicznym jest „linia bazowa, której nie pozwolono spróbować".

### A.2.2 Dopasuj budżety przy porównywaniu metod
Wydajność uczenia głębokiego często skaluje się silnie z:
- krokami treningowymi,
- wielkością zbioru danych,
- intensywnością augmentacji,
- wielkością modelu,
- mocą obliczeniową.

Dlatego, gdy porównujesz A vs. B, określ, co jest utrzymane na stałym poziomie:
- **stała moc obliczeniowa** (te same FLOPy/kroki/czas zegarowy), lub
- **stała wielkość modelu**, lub
- **stałe dane**, lub
- **stały cel wydajnościowy** (i porównaj koszt).

Jeśli nie zdefiniujesz budżetu, „lepszy" jest niejednoznaczny.

### A.2.3 Predefiniuj swoją regułę selekcji
Zdecyduj *przed* uruchomieniem:
- Jaka metryka określa „najlepszy checkpoint"?
- Na jakim podziale ta metryka jest obliczana?
- Jaka jest reguła zatrzymania (epoki, kroki, wczesne zatrzymanie)?
- Ile uruchomień wykonasz?

To zapobiega przypadkowej dominacji „stopni swobody badacza" nad wnioskami.

---

## A.3 Higiena danych: wyciek jest najczęstszym czynnikiem unieważniającym
Traktuj wyciek jako przeciwnika.

### A.3.1 Dziel na właściwej jednostce
W wielu domenach naiwne losowe podziały powodują wyciek tożsamości lub kontekstu:
- medycyna: dziel według **pacjenta**, nie obrazu
- systemy rekomendacyjne: dziel według **użytkownika** (i często według czasu)
- szeregi czasowe: dziel według **czasu**, nie losowego mieszania
- dane webowe: agresywnie deduplikuj między podziałami (niemal-duplikaty mają znaczenie)

### A.3.2 Utrzymuj zbiór testowy „martwy"
Martwy zbiór testowy to taki, który:
- nigdy nie jest używany do selekcji modelu,
- nigdy nie jest używany do wczesnego zatrzymania,
- nigdy nie jest używany do decydowania o wariantach preprocessingu,
- nigdy nie jest używany do dostrajania progów.

Jeśli wielokrotnie patrzysz na wydajność testową podczas iteracji, trenujesz na nim — tylko powoli.

### A.3.3 Obliczaj statystyki preprocessingu tylko na zbiorze treningowym
Częsty wzorzec wycieku:
- średnia/odchylenie standardowe normalizacji obliczone na pełnym zbiorze danych,
- słownik/tokenizer zbudowany przy użyciu tekstu testowego,
- selekcja cech wykonana przy użyciu etykiet ze wszystkich podziałów.

Zasada: **dopasowuj transformacje na zbiorze treningowym, aplikuj na walidacyjnym/testowym.**

### A.3.4 Uważaj na wyciek etykiet w inżynierii cech
Jeśli cecha jest wyprowadzona z czegokolwiek skorelowanego z etykietami ze względu na procedury zbierania, możesz uczyć procedurę, nie zjawisko.

Zapytaj: „Czy model mógłby odnieść sukces bez uczenia się zamierzonego sygnału?"

---

## A.4 Protokół treningowy: dokumentuj rzeczywistą procedurę, nie wyidealizowaną
Sekcja Metod uczenia głębokiego powinna umożliwiać odtworzenie uruchomienia treningowego, nie tylko jego ogólnej idei.

Minimum elementów do zapisania:
- architektura modelu i szczegóły inicjalizacji
- optymalizator + hiperparametry (włącznie z domyślnymi, których nie ruszałeś)
- harmonogram learning rate (dokładna forma + rozgrzewka)
- wielkość batcha (globalna i per urządzenie)
- liczba kroków/epok, akumulacja gradientów
- regularyzacja: weight decay, dropout, label smoothing, augmentacje
- ustawienia mixed precision (jeśli są)
- obcinanie gradientów
- reguła selekcji checkpointu
- losowe ziarna (i co inicjalizują)
- sprzęt i ustawienia rozproszone (liczba GPU, strategia)
- wersje bibliotek (framework, CUDA/cuDNN) gdzie istotne

### A.4.1 Tryb ewaluacji ma znaczenie (subtelny, ale częsty błąd)
Podczas ewaluacji:
- upewnij się, że dropout jest wyłączony,
- batch normalization używa odpowiednich bieżących statystyk,
- augmentacje są wyłączone, chyba że jawnie stosujesz test-time augmentation,
- mieszanie danych jest kontrolowane.

Niepoprawne tryby treningowe/ewaluacyjne mogą cicho unieważnić porównania.

---

## A.5 Dostrajanie hiperparametrów bez zanieczyszczania wniosków
### A.5.1 Budżet dostrajania powinien być opisany
Raportuj:
- które hiperparametry były dostrajane,
- metodę przeszukiwania (siatka, losowe, bayesowskie),
- budżet (próby, moc obliczeniowa),
- metrykę selekcji i podział.

Artykuł, który mówi „dostroiliśmy hiperparametry" bez budżetu, ma brakującą zmienną metodologiczną.

### A.5.2 Unikaj „dostrajania na zbiorze testowym przez niecierpliwość"
Jeśli wypróbowałeś 20 wariantów i raportujesz tylko ten, który najlepiej wypada na teście, wykonałeś niejawne testowanie wielokrotne.

Bezpieczniejsze wzorce:
- używaj walidacji dla wszystkich decyzji,
- zachowaj końcową ewaluację testową na koniec,
- rozważ drugi zbiór walidacyjny dla późnej iteracji (szczególnie w pracach o skali pracy dyplomowej).

---

## A.6 Stochastyczność: musisz ją mierzyć, nie zakładać, że nie istnieje
Uczenie głębokie jest szumowe. Pojedyncze uruchomienie jest często anegdotą.

### A.6.1 Minimalna praktyka
- uruchom wiele ziaren (często ≥3; więcej, jeśli wariancja jest wysoka),
- raportuj średnią ± zmienność (i/lub przedziały ufności),
- podaj, czy raportowana liczba to średnia, mediana, czy najlepszy z k.

### A.6.2 Selekcja ziarna jest znaną pułapką
Antywzorzec:
- uruchom wiele ziaren cicho i raportuj najlepsze.

Jeśli eksplorujesz wiele ziaren (do debugowania lub badań), bądź jawny:
- ile ziaren uruchomiono,
- co raportowano i dlaczego.

---

## A.7 Ablacje: poprawnie przypisuj usprawnienia
Ablacje odpowiadają na pytanie: „Który komponent spowodował zysk?"

Dobre ablacje:
- usuwają jeden komponent na raz,
- utrzymują stały budżet treningowy,
- ponownie dostrajają minimalnie i symetrycznie, jeśli to konieczne,
- raportują, czy komponent wchodzi w interakcje z innymi.

Ablacje, które zmieniają wiele rzeczy naraz, to opowieści, nie materiał dowodowy.

---

## A.8 Ewaluacja: metryki, kalibracja i solidność
### A.8.1 Używaj metryk zgodnych z rzeczywistym celem
Dokładność nie zawsze jest istotna. Rozważ:
- niezbalansowanie klas (użyj F1, AUROC, AUPRC, balanced accuracy)
- problemy rankingowe (NDCG, MAP)
- kalibracja (ECE, Brier score, diagramy niezawodności)
- błędy wrażliwe na koszt (metryki ważone)

### A.8.2 Progi muszą być wybrane prawidłowo
Jeśli próg klasyfikatora jest wybierany przy użyciu etykiet testowych, zbiór testowy nie jest już zbiorem testowym.

Zasada: wybieraj progi na walidacji, następnie aplikuj na teście.

### A.8.3 Sprawdzenia solidności (często tanie, wysoce informacyjne)
- testy perturbacyjne (szum, rozmycie, kompresja)
- analizy podgrup (jeśli etycznie i statystycznie odpowiednie)
- sondy poza dystrybucją (jasno oznaczone jako takie)
- sprawdziany zdrowego rozsądku (poniżej)

---

## A.9 Sprawdziany zdrowego rozsądku, które wyłapują zaskakująco wiele błędów
To są „sondy rzetelności", nie opcjonalna uprzejmość.

- **Przeuczenie na małym podzbiorze:** czy model może osiągnąć niemal idealną wydajność treningową na ~50–200 przykładach? Jeśli nie, coś jest zepsute.
- **Test tasowania etykiet:** jeśli przetasujesz etykiety, wydajność powinna spaść do losowej.
- **Ablacja wejścia:** usuń sygnał, który twierdzisz, że ma znaczenie; wydajność powinna się pogorszyć.
- **Sprawdzenie zgodności trening/walidacja:** jeśli trening się poprawia, ale walidacja nie, zbadaj wyciek, przeuczenie lub niedopasowanie metryki.
- **Reprodukcja linii bazowej:** czy możesz odtworzyć znaną liczbę linii bazowej z literatury lub własnego wcześniejszego uruchomienia?

---

## A.10 Pakiet odtwarzalności: jak wygląda „kompletność" w praktyce
Silny pakiet odtwarzalności często zawiera:
- pojedyncze polecenie do uruchomienia treningu (lub jasny potok skryptów)
- plik środowiska/specyfikacja kontenera
- stałe wersjonowanie zbioru danych (hashe, manifest)
- pliki konfiguracyjne dla wszystkich eksperymentów
- logi (włącznie z nieudanymi uruchomieniami, gdzie istotne)
- skrypty ewaluacyjne regenerujące tabele/ryciny z checkpointów

Zasada: wynik nie jest w pełni naukowy, dopóki ścieżka od surowych wejść do raportowanych liczb nie jest audytowalna.

---

## A.11 Typowe błędy metodologiczne uczenia głębokiego (lista diagnostyczna)
Jeśli którykolwiek element poniżej jest prawdziwy, traktuj wyniki jako prowizoryczne do naprawienia:

- Zbiór testowy używany do wczesnego zatrzymania lub selekcji modelu  
- Preprocessing danych dopasowany na pełnym zbiorze danych (włącznie z testem)  
- Podział wykonany na niewłaściwej jednostce (wyciek tożsamości/czasu)  
- Linia bazowa niedodostrojona względem proponowanej metody  
- Raportowane tylko najlepsze ziarno bez ujawnienia  
- Przestrzeń przeszukiwania hiperparametrów nieraportowana (lub efektywnie nieograniczona)  
- Zmiany kodu w trakcie eksperymentu bez kontroli wersji / identyfikatorów uruchomień  
- Ewaluacja wykonana z niezamierzenie włączonymi augmentacjami  
- Model ewaluowany w trybie treningowym (problemy dropout/BN)  
- Zbiór danych zawiera duplikaty między podziałami (dokładne lub niemal-duplikaty)  
- Metryka wybrana po obejrzeniu wyników („shopping metryczny")

---

## A.12 Minimalna lista kontrolna „rzetelnego wyniku" (do druku)
Zanim uwierzysz własnej liczbie, zweryfikuj:

- [ ] Twierdzenie jest jasno sformułowane i odpowiada metryce  
- [ ] Zbiór testowy nie był używany do żadnej decyzji  
- [ ] Podziały zapobiegają wyciekowi tożsamości/czasu  
- [ ] Preprocessing był dopasowany tylko na zbiorze treningowym  
- [ ] Linie bazowe były dostrajane z porównywalnym wysiłkiem  
- [ ] Uruchomiono wiele ziaren (lub wariancja jest inaczej uzasadniona)  
- [ ] Sprawdziany zdrowego rozsądku przechodzą (małe przeuczenie, tasowanie etykiet)  
- [ ] Dokładne konfiguracje, wersje i budżety są zapisane  
- [ ] Ryciny/tabele można zregenerować z logów/checkpointów  

---

# Aneks B — Agentowa sztuczna inteligencja: Ewaluacja systemów bez autooszukiwania

## B.0 Dlaczego agentowa AI jest metodologicznie trudna
Systemy „agentowej AI" — LLM lub inne polityki, które planują, używają narzędzi, wywołują API, piszą kod, przeglądają, przechowują pamięć i działają przez wiele kroków — wprowadzają tryby awarii, których standardowa ewaluacja modeli nie pokrywa.

W pracy agentowej niezwykle łatwo jest:
- pomylić *demo* z *wynikiem*,
- pozwolić agentowi przypadkowo uzyskać dostęp do klucza odpowiedzi,
- dostrajać na benchmarku poprzez iterację promptów,
- raportować nieodtwarzalny sukces, ponieważ środowisko się zmieniło,
- używać subiektywnych sędziów LLM bez kontroli niezawodności,
- tworzyć imponujące zachowanie, które jest w rzeczywistości kruche lub niebezpieczne.

Ten aneks dostarcza pragmatycznej metodologii dla utrzymania rzetelności wyników.

---

## B.1 Zdefiniuj obiekt badania: model vs. agent vs. system
Bądź jednoznaczny, czy ewaluujesz:
- **Zdolność modelu bazowego:** co model może zrobić przy danym prompcie.
- **Politykę agenta:** logikę decyzyjną przez kroki (planowanie, wywołania narzędzi, użycie pamięci).
- **Pełny system:** polityka + narzędzia + retrieval + środowisko + zabezpieczenia + ograniczenia budżetowe.

Wynik systemu („działa end-to-end") nie może być przypisany nowemu algorytmowi planowania, chyba że pokażesz ablacje.

---

## B.2 Określ środowisko jako część Metod
Wydajność agenta zależy krytycznie od szczegółów środowiska:
- zestaw narzędzi i interfejsy narzędzi (wersje mają znaczenie)
- dostępność dostępu do internetu (lub sandboxowe korpusy)
- opóźnienia, timeouty, limity rate
- obsługa błędów
- zachowanie resetowania między epizodami
- ukryty stan (cache, trwałe pliki, magazyn pamięci)

**Zasada:** Jeśli środowisko może się zmienić, twoja ewaluacja może dryfować. Dokumentuj środowisko jak sprzęt laboratoryjny.

---

## B.3 Problem „klucza odpowiedzi": zapobiegaj niezamierzonemu dostępowi do informacji
Systemy agentowe są wyjątkowo podatne na oszukiwanie (często niezamierzone).

### B.3.1 Typowe ścieżki wycieku
- Korpus retrieval zawiera rozwiązania lub wyjaśnienia benchmarku  
- Narzędzia pozwalają przeszukiwać repozytorium benchmarku  
- Dostęp do internetu pozwala znaleźć odpowiedzi benchmarku online  
- Magazyny pamięci akumulują rozwiązania testowe między uruchomieniami  
- Logi z poprzednich uruchomień są widoczne dla agenta  
- Harness ewaluacyjny zawiera wskazówki lub ground truth w wyjściach narzędzi  
- Prompt zawiera przykłady, które pokrywają się z zadaniami testowymi

### B.3.2 Praktyczne reguły izolacji
- Oddzielaj **zadania developmentowe** od **zadań testowych** ściśle.
- Uruchamiaj ewaluację w sandboxie, gdzie agent nie może czytać:
  - etykiet testowych,
  - ukrytych testów jednostkowych (dla zadań kodowania),
  - plików rozwiązań benchmarku,
  - skryptów oceniających.
- Czyść lub wersjonuj magazyny pamięci; nie pozwalaj im cicho persistować między epizodami ewaluacyjnymi, chyba że to jest jawnie warunek eksperymentalny.

---

## B.4 Metryki sukcesu muszą obejmować koszt i niezawodność
Ewaluacja agenta powinna zazwyczaj raportować co najmniej:
- **Współczynnik sukcesu zadań** (z jasnymi kryteriami sukcesu)
- **Koszt** (tokeny, wywołania narzędzi, czas zegarowy, moc obliczeniowa)
- **Niezawodność** (wariancja między uruchomieniami/ziarnami)
- **Tryby awarii** (kategorie: błąd narzędzia, błąd planowania, halucynacja, odmowa bezpieczeństwa, itp.)

System, który odnosi sukces raz, ale zawodzi nieprzewidywalnie, nie jest solidny. Traktuj niezawodność jako metrykę główną, nie refleksję.

---

## B.5 Niedeterminizm: ewaluuj przez uruchomienia, nie anegdoty
Agenty są stochastyczne w wielu miejscach:
- próbkowanie modelu (temperatura, top-p)
- niedeterminizm narzędzi/API (wyniki wyszukiwania, zmiany treści webowych)
- współbieżność i timeouty

Minimalna praktyka:
- ustal ziarna gdzie możliwe (i podaj, co jest i nie jest kontrolowane przez ziarno)
- uruchom wiele prób na zadanie
- raportuj rozkłady (nie tylko wyniki najlepszego przypadku)

Jeśli system jest zaprojektowany jako stochastyczny (np. eksploracja), twoja ewaluacja musi mierzyć oczekiwaną wydajność i wariancję.

---

## B.6 Projekt benchmarku i zestawu zadań: unikaj budowania „klucza w kształcie benchmarku"
### B.6.1 Separacja dev/test jest nienegocjowalna
Iteracja promptu na benchmarku to trening. Może to być uzasadniona inżynieria, ale nie jest czystym testem naukowym, chyba że zachowasz nietknięty zbiór testowy.

Praktyczny wzorzec:
- **Zbiór dev:** używany do iteracji promptu/systemu  
- **Zbiór walidacyjny:** używany do wyboru wariantów  
- **Zbiór testowy:** używany raz do końcowego raportowania  

Jeśli nie możesz sobie pozwolić na trzy podziały, przynajmniej wymuś: *dev ≠ test*.

### B.6.2 Kontroluj trudność i niejednoznaczność
Agenty często wyglądają dobrze na zadaniach, które są niedospecyfikowane. Zdefiniuj:
- co liczy się jako sukces,
- co stanowi częściowe zaliczenie (jeśli w ogóle),
- limity czasu/kosztu na epizod,
- dozwolone użycie narzędzi.

Niejednoznaczność nie jest inherentnie zła, ale musi być uznana i obsługiwana konsekwentnie.

---

## B.7 Linie bazowe dla systemów agentowych (i jak uczynić je uczciwymi)
Usprawnienia agentów łatwo przesadzić, ponieważ możesz porównywać ze słabymi liniami bazowymi.

Zalecany zestaw linii bazowych (dostosuj do domeny):
- **Bezpośredni LLM (bez narzędzi):** linia bazowa single-shot lub few-shot prompt  
- **LLM + retrieval (bez planowania wielokrokowego):** izoluje wartość retrieval  
- **Użycie narzędzi bez planowania (stały skrypt):** izoluje wartość planowania  
- **Silna publiczna linia bazowa agenta:** jeśli dostępna, skonfigurowana uczciwie  
- **Narzędzia oracle (opcjonalnie, jasno oznaczone):** oszacowuje górną granicę

Reguły uczciwości:
- podobne ograniczenia budżetowe,
- podobny dostęp do narzędzi,
- porównywalny wysiłek dostrajania promptu (lub raportuj budżety dostrajania jawnie).

---

## B.8 Ablacje: traktuj prompty i scaffolding jak kod
W systemach agentowych „prompt" to nie tylko tekst; to część algorytmu.

Dlatego:
- kontroluj wersje promptów i wiadomości systemowych
- abluj moduły planowania, pamięć, retrieval, podzbiory narzędzi
- testuj wrażliwość na sformułowanie promptu (solidność)
- raportuj dokładny użyty prompt (lub zasadną redakcję, jeśli wrażliwy)

System, który działa tylko z jedną magiczną inkantacją, jest kruchy; kruchość jest wynikiem, ale musi być raportowana uczciwie.

---

## B.9 Ewaluacja LLM-jako-sędzia: używaj ostrożnie lub pożałujesz później
Sędziowie LLM mogą być użyteczni, ale wprowadzają obciążenie i nieodtwarzalność.

Jeśli używasz sędziego LLM:
- zdefiniuj rubrykę precyzyjnie (co liczy się jako poprawne)
- utrzymuj prompty sędziego stałe i wersjonowane
- oceniaj niezawodność sędziego (zgodność z ludźmi na podzbiorze)
- rozważ wielu sędziów lub głosowanie większościowe dla stabilności
- unikaj oceniania tym samym modelem, który ewaluujesz (konflikt interesów w narzędziu pomiarowym)

Gdy obiektywna ewaluacja jest możliwa (testy jednostkowe, dokładne dopasowania, strukturyzowane wyjścia), preferuj ją.

---

## B.10 Dryf środowiska: „żywa sieć" nie jest stabilnym benchmarkiem
Jeśli twój agent używa otwartego internetu:
- strony się zmieniają,
- rankingi wyszukiwania się zmieniają,
- API się zmieniają,
- treści znikają.

To może być akceptowalne dla *demonstracji systemu*, ale jest niestabilne dla twierdzeń naukowych, chyba że:
- zrobisz snapshot treści,
- ograniczysz do stałego korpusu,
- lub potraktujesz ewaluację jako oznaczoną czasowo i nieporównywalną między datami.

Bądź jednoznaczny: *Czy to benchmark czy demo?* Obie mogą być wartościowe, ale są różnymi obiektami epistemicznymi.

---

## B.11 Bezpieczeństwo jest częścią poprawności metodologicznej
Systemy agentowe wchodzą w interakcje z narzędziami i środowiskami, które mogą być adwersarialne.

### B.11.1 Wstrzykiwanie promptów i ataki przez wyjścia narzędzi
Strony webowe lub wyjścia narzędzi mogą zawierać instrukcje, które przejmują zachowanie.
Implikacja metodologiczna: agent, który „odnosi sukces" poprzez podążanie za złośliwymi instrukcjami, może wydawać się zdolny, będąc niebezpiecznym.

Środki zaradcze (raportuj je):
- sanityzacja wyjść narzędzi
- reguły hierarchii instrukcji (system > developer > użytkownik > narzędzie)
- ograniczone uprawnienia narzędzi
- sandboxing
- jawne polityki odmowy dla niebezpiecznych działań

### B.11.2 Granice uprawnień
Nie ewaluuj agentów w sposób, który daje im uprawnienia, których rzeczywiste wdrożenie by nie miało (dostęp do systemu plików, klucze prywatne, nieograniczona sieć). To może zawyżać wydajność i maskować ryzyko.

---

## B.12 Logowanie i śledzalność: transkrypty to twoja sekcja Metod
Dla systemów agentowych zapis eksperymentu to nie tylko kod i konfiguracje. To także:
- pełne prompty
- ślady akcji (wywołania narzędzi, argumenty, wyjścia)
- pośrednie myśli *jeśli je logujesz* (opcjonalne; traktuj prywatność ostrożnie)
- końcowe wyjścia
- wyjścia ewaluatora i wyniki

Wynik bez śladów jest trudny do audytu. Ślad bez wersjonowanych konfiguracji jest trudny do odtworzenia. Potrzebujesz obu.

---

## B.13 Typowe sposoby, w jakie eksperymenty agentowe stają się nieważne (bezpośrednia lista)
Traktuj swoją ewaluację jako skompromitowaną, jeśli którekolwiek z poniższego miało miejsce bez ujawnienia i korekty:

- Agent może uzyskać dostęp do odpowiedzi benchmarku przez retrieval lub web  
- Prompt/przykłady pokrywają się z zadaniami testowymi  
- Zbiór testowy używany wielokrotnie podczas iteracji („dostrajanie promptu na teście")  
- Pamięć persistuje między epizodami testowymi niezamierzenie  
- Środowisko ewaluacyjne nie resetowane prawidłowo między uruchomieniami  
- Zachowanie narzędzi zmienia się między uruchomieniami (wersje API, dryf treści)  
- Kryteria sukcesu są niejasne lub niespójnie stosowane  
- Sędzia LLM używany bez sprawdzeń niezawodności  
- Pokazano tylko wyselekcjonowane demo, podczas gdy współczynnik awarii jest ukryty  
- Ograniczenia budżetowe nie egzekwowane (nieograniczone ponowne próby/wywołania narzędzi)  
- Interwencje ludzkie występują w trakcie uruchomienia i nie są raportowane  

---

## B.14 Minimalna lista kontrolna „rzetelnej ewaluacji agenta" (do druku)
Zanim zaufasz swoim wynikom agenta:

- [ ] Ewaluowany obiekt jest zdefiniowany (model vs agent vs system)  
- [ ] Narzędzia, środowisko i budżety są udokumentowane i wersjonowane  
- [ ] Separacja dev/val/test jest egzekwowana  
- [ ] Agent nie może uzyskać dostępu do odpowiedzi (brak ścieżek wycieku)  
- [ ] Ewaluacja obejmuje sukces + koszt + niezawodność  
- [ ] Uruchomiono wiele prób na zadanie (stochastyczność zmierzona)  
- [ ] Linie bazowe są konkurencyjne i dostrojone uczciwie  
- [ ] Ablacje izolują, które komponenty mają znaczenie  
- [ ] Ocenianie jest obiektywne gdy możliwe; sędziowie LLM są zwalidowani jeśli używani  
- [ ] Pełne ślady są logowane dla audytowalności  

---
